## ROC曲线和P-R曲线

很多分类器为测试样本得到一个预测概率p ( 0≤p≤1 )，将这个预测概率从大到小进行排序，排在前面的是分类器认为“最可能”需要预刷的图卡，排在后面的则是分类器认为“最不可能”需要预刷的图卡。然后在 [0, 1] 区间内选择一个阈值，如果预测概率大于该阈值，则将样本判定为需要预刷的图卡，反之则判定为不需要预刷的图卡。这样可以得到很多组混淆矩阵，都可以计算上述指标，用于绘制ROC曲线与P-R曲线。

- ROC曲线：以TPR（缓存命中率）为y轴，以FPR（cost1）为x轴，就得到了ROC曲线。从FPR和TPR的定义可以理解，TPR越高，FPR越小，我们的模型和算法就越高效。也就是画出来的ROC曲线越靠近左上越好。如下图左图所示，从几何的角度讲，ROC曲线下方的面积越大，则模型越优。所以有时候我们用ROC曲线下的面积，即AUC（Area Under Curve）值来作为算法和模型好坏的标准。
- PR曲线：以精确率（预刷有效率）为y轴，以召回率（缓存命中率）为x轴，就得到了PR曲线。仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近右上越好。如下图右图所示。
- PR和ROC主要区别：PR曲线比ROC曲线更加关注正样本，而ROC则兼顾了两者。

![roc和p-r曲线](https://img2018.cnblogs.com/blog/1102791/201812/1102791-20181226105734428-906065004.png)

## 模型解释-SHAP

[shap介绍](https://zhuanlan.zhihu.com/p/83412330)

```python
import shap
shap.initjs()

explainer = shap.TreeExplainer(lgbm_0)
shap_values = explainer.shap_values(x_train[features])
shap.summary_plot(shap_values, x_train[features])
```