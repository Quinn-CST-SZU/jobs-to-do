## 1.功能

｜ 特性 ｜ 说明 ｜
｜ - ｜ - ｜
｜ 多数据源 ｜ 目前presto可以支持MySQL、PostgreSQL、Cassandra、Hive、Kafaka、JMX等多种Connector，除此之外，京东商城改造之后的Presto也能够很好地支持Oracle、SQLServer，并且可以支持分库分表以及数据快速读取的功能 ｜
｜ 支持SQL ｜ Presto已经可以完全支持ANSI SQL，并提供了一个SQL Shell给用户，用户可以直接使用ANSI SQL进行数据查询和计算 ｜
｜ 扩展性 ｜ Presto有很好的扩展性，开发人员可以很容易地开发出适用于自己特定数据源的Connector，并且可以使用SQL语句查询和分析自定义的Connector中的数据 ｜
｜ 混合计算 ｜ 在数据库中没重类型的数据源都对应于一种特定类型的Connector，用户可以根据业务需要在Presto中针对于一种类型的Connector配置一种或者多个Catalog，并查询其中的数据，用户可以混合多个Catalog进行join查询和计算 ｜
｜ 高性能 ｜ 经过Facebook和京东商城的测试，Presto的查询的平均性能是Hive的10倍以上 ｜
｜ 流水线 ｜ 由于Presto是基于PipeLine进行设计的，因此在进行海量数据处理的过程中，终端用户不用等到所有的数据都处理完毕才看到结果，儿使可以像自来水管道一样，一旦计算开始，就可以立即产生一部分的结果数据，并且结果数据会一部分接一部分地呈现在终端客户面前 ｜

## 2.基本概念

### 2.1 服务进程

- Coordinator进程： 接受查询请求，解析查询语句，生成查询执行计划，任务调度，Worker管理。
- Worker进程： 执行被分解后端而查询执行任务–>Task


### 2.2 Presto模型
- Connector Presto访问不同数据源的驱动程序。每种Connector都实现Presto中标准SPI接口。当年需要使用某种Connector访问特定的数据源时，需要在$PRESTO_HOME/etc/catalog中配置文件：example.properties,并在配置文件中设置一个属性：connector.name,Presto中Connector Manager就是通过该配置属性来决定使用哪一个Connector去访问数据。
- Catalog 对应某一类数据源，例如hive的数据，或mysql的数据。当你访问Catalog中某个表时，该表的全名总是以Catalog的名字开始。例如 名字为example.schema1.table1的表，指的是表table1位于名schema1下的schema中，而schema1又位于example的Catalog中。
- Schema 对应mysql中的数据库
- Table 对应mysql中的表

### 2.3 Presto查询步骤

1) 客户端通过Http协议发送一个查询语句给Presto集群的Coordinator
2) Coordinator收到客户端传递过来的查询语句，会对该查询语句进行解析，生成查询执行计划，并根据查询执行计划一次生成SqlQueryExecution，SqlStageExecution，HttpRemoteTask。Coordinator会根据数据本地行生成对应的HttpRemoteTask。
3) Coordiantor将每一个Task都分发到其所需要处理的数据所在的Worker上进行执行。这个过程是通过HttpRemoteTask中的HttpClient将创建或者更新Task请求发送给数据所在节点上TaskResource所提供的Restful接口，TaskResource接收到请求之后最终会在对应的Worker上启动一个SqlTaskExecution对象或者更新对应的SqlTaskExecution对象需要处理的Split。
4) 执行处于上游的Source Stage中的Task,这些Task通过各种Connector从相应的数据源中读取所需要的数据。
5) 处于下游的会读取上有Stage产生的输出结果，并在该Stage每隔Task所在Worker的内存中进行后续的计算和处理。
6) Coordinator从分发的Task之后，就会一直持续不断的从Single Stage中的Task获取计算结果，并将计算结果缓存到Buffer中，直到所有的计算结束。
7) Client从提交查询语句之后，就会不断地从Coordinator中获取本次查询的计算结果，直到获得了所有的计算记过。并不是等到所有的查询结果都产生完毕之后一次全部显示出来，而是每产生一部分，就会显示一部分，直到所有的查询结果都显示完毕。